{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions:\n",
    "## 1. What's the filter on the key words? \n",
    "### Here's the text of the first tweet, looks it's not that relevant to Boeing.\n",
    "### \"RT @SheliaBurk: @BillWrh1970 @bfraser747 @KellyannePolls He has good relations with Muslims though, doesn't he? How could people no\\u2026 \"\n",
    "## 2. How to remove emoticons like :) :D ?\n",
    "## 3. What is the time zone of `timestamp ms` and `created_at`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil import tz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/ggao/Documents/boeing777/boeing/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q1: what's the filter? why they're relevant?\n",
    "# First tweet text:\n",
    "# \"RT @SheliaBurk: @BillWrh1970 @bfraser747 @KellyannePolls He has good relations with Muslims though, doesn't he? How could people no\\u2026 \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_list = os.listdir(path)\n",
    "# Just to run a small sample first\n",
    "file_list = [file_list[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(file_list)):\n",
    "    with open(path + file_list[i]) as input_file:\n",
    "        temp_data = pickle.load(input_file)\n",
    "    data += temp_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "282"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Need to double check the timezone of 'timestamp_ms' and 'created_at'\n",
    "from_zone = tz.gettz('UTC')\n",
    "to_zone = tz.gettz('America/New_York')\n",
    "\n",
    "# utc = datetime.utcnow()\n",
    "utc = datetime.fromtimestamp(int(data[0]['timestamp_ms']) / 1000)\n",
    "\n",
    "# Tell the datetime object that it's in UTC time zone since \n",
    "# datetime objects are 'naive' by default\n",
    "utc = utc.replace(tzinfo=from_zone)\n",
    "\n",
    "# Convert time zone\n",
    "central = utc.astimezone(to_zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'user_mentions', u'symbols', u'hashtags', u'urls']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][u'entities'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'id': 889148660,\n",
       "  u'id_str': u'889148660',\n",
       "  u'indices': [3, 14],\n",
       "  u'name': u'\\U0001f1fa\\U0001f1f8Shelia Burk\\U0001f1fa\\U0001f1f8',\n",
       "  u'screen_name': u'SheliaBurk'},\n",
       " {u'id': 347291458,\n",
       "  u'id_str': u'347291458',\n",
       "  u'indices': [16, 28],\n",
       "  u'name': u'Bill (WildBill)',\n",
       "  u'screen_name': u'BillWrh1970'},\n",
       " {u'id': 274891222,\n",
       "  u'id_str': u'274891222',\n",
       "  u'indices': [29, 40],\n",
       "  u'name': u'Brian Fraser',\n",
       "  u'screen_name': u'bfraser747'},\n",
       " {u'id': 471672239,\n",
       "  u'id_str': u'471672239',\n",
       "  u'indices': [41, 56],\n",
       "  u'name': u'Kellyanne Conway',\n",
       "  u'screen_name': u'KellyannePolls'}]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][u'entities']['user_mentions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'contributors',\n",
       " u'truncated',\n",
       " u'text',\n",
       " u'is_quote_status',\n",
       " u'in_reply_to_status_id',\n",
       " u'id',\n",
       " u'favorite_count',\n",
       " u'source',\n",
       " u'retweeted',\n",
       " u'coordinates',\n",
       " u'timestamp_ms',\n",
       " u'entities',\n",
       " u'in_reply_to_screen_name',\n",
       " u'in_reply_to_user_id',\n",
       " u'retweet_count',\n",
       " u'id_str',\n",
       " u'favorited',\n",
       " u'retweeted_status',\n",
       " u'user',\n",
       " u'geo',\n",
       " u'in_reply_to_user_id_str',\n",
       " u'lang',\n",
       " u'created_at',\n",
       " u'filter_level',\n",
       " u'in_reply_to_status_id_str',\n",
       " u'place']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2017, 1, 1, 0, 34, 16)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Default timestamp \n",
    "datetime.fromtimestamp(int(data[1]['timestamp_ms']) / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For each tweet, get the time -- truncated to day? and the tokenized tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RT', '@', 'marcobonzanini', ':', 'just', 'an', 'example', '!', ':', 'D', 'http', ':', '//example.com', '#', 'NLP']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    " \n",
    "tweet = 'RT @marcobonzanini: just an example! :D http://example.com #NLP'\n",
    "print(word_tokenize(tweet))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RT', ':', 'this', 'is', 'just', 'an', 'example', '!', ':D', 'NLP']\n",
      "['example', ':D', 'nlp']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    " \n",
    "punctuation = list(string.punctuation)\n",
    "stopwords_list = stopwords.words('english') + punctuation + ['rt', 'via']\n",
    "\n",
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    " \n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    " \n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "    \n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    " \n",
    "def tokenize(s):\n",
    "    # remove emojis\n",
    "    emojis_re = re.compile(\n",
    "    u\"(\\ud83d[\\ude00-\\ude4f])|\"  # emoticons\n",
    "    u\"(\\ud83c[\\udf00-\\uffff])|\"  # symbols & pictographs (1 of 2)\n",
    "    u\"(\\ud83d[\\u0000-\\uddff])|\"  # symbols & pictographs (2 of 2)\n",
    "    u\"(\\ud83d[\\ude80-\\udeff])|\"  # transport & map symbols\n",
    "    u\"(\\ud83c[\\udde0-\\uddff])\"  # flags (iOS)\n",
    "    \"+\", flags=re.UNICODE)\n",
    "    \n",
    "    tokens = emojis_re.sub(r'', s)\n",
    "    # remove hash-tag and mentions \n",
    "    tokens = re.sub(r\"(?:\\#)\" + '|' + r'(?:@[\\w_]+)', '', tokens)\n",
    "    # remove URL\n",
    "    tokens = re.sub(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+' + '|' + r'<[^>]+>', '', tokens)\n",
    "    # Q2: how to remove emoticons like :) :D\n",
    "    \n",
    "    tokens = tokens_re.findall(tokens)\n",
    "    # Filter non stopwords, and the words starting with @\n",
    "    print tokens\n",
    "    tokens = [item for item in tokens if item.lower() not in stopwords_list]\n",
    "    return tokens\n",
    " \n",
    "def preprocess(s, lowercase=False):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        # If it's emoticon then do not return lowercase\n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "    return tokens\n",
    " \n",
    "tweet = 'RT @marcobonzanini: this is just an example! :D http://example.com #NLP'\n",
    "print(preprocess(tweet, lowercase=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'jk', 'h', 's', 'k', 'hw', 'iuh', 'oi']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a through f: [] represents a range\n",
    "# Is two consecutive characters then use two ranges [a-f][a-f]\n",
    "re.split(r'[a-fA-F]', 'ajkfhdsakFhweiuhfoi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adjfjadklsf fdasklfdj'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \\d{1,5} : digits length 1 to 5\n",
    "# +: 1 or more\n",
    "# .* anything\n",
    "# \\w alphanumeric (either letter or number)\n",
    "re.sub(r'\\d{1,5}\\s\\w+\\s\\w+\\.', ' ', 'adjfjadklsf475 wahsington st.fdasklfdj', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
